{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL : Tensorflow basic computation using single CPU or GPU\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The aim of this tutorial is to use `AI TRAINING` product to do a **very simple tensor computation** with the `Tensorflow` library and to compare performances of running it over CPU versus GPU.\n",
    "\n",
    "## Prerequities\n",
    "\n",
    "* a Public cloud project\n",
    "* an `AI-TRAINING` notebook job launched with the `Tensorflow 2` preset image ([documentation available here](https://docs.ovh.com/gb/en/ai-training/start-use-notebooks/))\n",
    "* the notebook resources should have at least 1 GPU\n",
    "\n",
    "## In practice\n",
    "\n",
    "### Step 1: Import Tensorflow library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "GPU_DEVICES = tf.config.list_logical_devices('GPU')\n",
    "GPU_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num of GPUs available: \", len(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 : Check that you have GPU(s) available on your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of all logical GPU device on your notebook\n",
    "GPU_DEVICES = tf.config.list_logical_devices('GPU')\n",
    "# Get the list of all logical CPU device on your notebook\n",
    "CPU_DEVICES = tf.config.list_logical_devices('CPU')\n",
    "# Keep only the names of each GPU devices\n",
    "GPU_DEVICES_NAMES = [x.name for x in GPU_DEVICES]\n",
    "# Keep only the names of each CPU devices\n",
    "CPU_DEVICES_NAMES = [x.name for x in CPU_DEVICES]\n",
    "# The number of GPU devices\n",
    "GPU_DEVICES_NB = len(GPU_DEVICES)\n",
    "# The number of CPU devices\n",
    "CPU_DEVICES_NB = len(CPU_DEVICES)\n",
    "\n",
    "if GPU_DEVICES_NB == 0:\n",
    "    raise SystemError('No GPU device found')\n",
    "else:\n",
    "    print(f'{GPU_DEVICES_NB} GPU device(s) have been found on your notebook :')\n",
    "\n",
    "for nb in range(GPU_DEVICES_NB):\n",
    "    gpu_name = GPU_DEVICES_NAMES[nb]\n",
    "    print(f'* GPU n°{nb} whose name is \"{gpu_name}\"')\n",
    "    \n",
    "print('')\n",
    "    \n",
    "if CPU_DEVICES_NB == 0:\n",
    "    raise SystemError('No CPU device found')\n",
    "else:\n",
    "    print(f'{CPU_DEVICES_NB} CPU device(s) have been found on your notebook :')\n",
    "\n",
    "for nb in range(CPU_DEVICES_NB):\n",
    "    cpu_name = CPU_DEVICES_NAMES[nb]\n",
    "    print(f'* CPU n°{nb} whose name is \"{cpu_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 : Define the operation to benchmark\n",
    "\n",
    "Here we choose to define a simple function that multiply 2 random vectors of the given length. This is the function that we are going to benchmark over available devices (GPU and CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_multiply(vector_length):\n",
    "    vector_1 = tf.random.normal(vector_length)\n",
    "    vector_2 = tf.random.normal(vector_length)\n",
    "    return vector_1 * vector_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Define the function executing the operation on GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_operation(vector_length):\n",
    "    # If you have several GPU you can select the one to use by changing the used index of GPU_DEVICES_NAMES\n",
    "    with tf.device(GPU_DEVICES_NAMES[0]):\n",
    "        random_multiply(vector_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Define the function executing the operation on CPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpu_operation(vector_length):\n",
    "    # If you have several CPU you can select the one to use by changing the used index of GPU_DEVICES_NAMES\n",
    "    with tf.device(CPU_DEVICES_NAMES[0]):\n",
    "        random_multiply(vector_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step6 : Launch the benchmark of each device over several vectors of different lengths\n",
    "\n",
    "Here we are going to iterate over several lengths of vectors and launch a benchmark both on GPU and CPU to observe on which cases GPU is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu_operation([1])\n",
    "gpu_operation([1])\n",
    "\n",
    "for i in range(8):\n",
    "    vector_length = pow(10, i)\n",
    "    cpu_time = timeit.timeit(f'cpu_operation([{vector_length}])', number=20, setup=\"from __main__ import cpu_operation\")\n",
    "    gpu_time = timeit.timeit(f'gpu_operation([{vector_length}])', number=20, setup=\"from __main__ import gpu_operation\")\n",
    "    print(f'Operations on vector of length {vector_length} are {cpu_time/gpu_time}x faster on GPU than CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can conclude :\n",
    "* Computation of scalars (i.e vectors of lenght 1) are more efficient on CPU than GPU\n",
    "* Computation of vectors are quite as efficient on CPU or GPU when length is between 10 and 1000\n",
    "* Computation of vectors whose length is higher than 1000 are much more efficient on GPU than CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further\n",
    "\n",
    "* For more information about running computations over GPU with TensorFlow we advise you to follow the [official documentation](https://www.tensorflow.org/guide/gpu)\n",
    "* **Resource consumption** of your notebook is displayed in a dashboard that you can see. **Just execute the following cells to get the URL corresponding to your notebook** session. The credencials needed to access this dashboard are the same than those used for the current notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if 'NOTEBOOK_ID' in os.environ:\n",
    "    VARID = \"var-notebook=\" + os.environ['NOTEBOOK_ID']\n",
    "    HOST = os.environ['NOTEBOOK_HOST']\n",
    "    SUBDOMAIN = \"notebook\"\n",
    "else:\n",
    "    VARID =  \"var-job=\" + os.environ['JOB_ID']\n",
    "    HOST = os.environ['JOB_HOST']\n",
    "    SUBDOMAIN = \"job\"\n",
    "\n",
    "\n",
    "print(f'Your resource monitoring dashboard URL is :')\n",
    "print(f'http://{HOST.replace(SUBDOMAIN, \"monitoring\")}/d/gpu/job-monitoring?orgId=1&from=now-5m&{VARID}&to=now')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
